behaviors:
  worm_easy:
    trainer_type: ppo
    hyperparameters:
      batch_size: 1024                # Number of experiences used for each iteration of gradient descent.
      buffer_size: 10240              # Number of experiences to collect before updating the model.
      learning_rate: 3.0e-4           # Learning rate for the optimizer.
      beta: 5.0e-4                    # Strength of entropy regularization.
      epsilon: 0.2                    # Clipping parameter for PPO.
      lambd: 0.95                     # Lambda parameter for GAE (Generalized Advantage Estimation).
      num_epoch: 3                    # Number of passes through the experience buffer during gradient descent.
      learning_rate_schedule: linear  # How the learning rate changes over time.
    
    network_settings:
      normalize: true                 # Normalize observations.
      hidden_units: 256               # Number of units in each fully connected layer of the neural network.
      num_layers: 2                   # Number of hidden layers in the neural network.
      # vis_encode_type: simple       # Encoding type for visual observations (simple or resnet).
    
    reward_signals:
      extrinsic:
        gamma: 0.99                   # Discount factor for future rewards.
        strength: 1.0                 # Reward signal strength.

    keep_checkpoints: 50              # Number of model checkpoints to keep.
    max_steps: 50000000               # Total number of training steps.
    time_horizon: 512                 # Time horizon for accumulating experiences before making an update.
    summary_freq: 5000                # Frequency of writing statistics to TensorBoard.
    checkpoint_interval: 1000000      # Frequency of model checkpoint saving.
    threaded: false                   # Whether to use multi-threaded simulation.
    
  worm_medium:
    trainer_type: ppo
    hyperparameters:
      batch_size: 1024                # Number of experiences used for each iteration of gradient descent.
      buffer_size: 10240              # Number of experiences to collect before updating the model.
      learning_rate: 3.0e-4           # Learning rate for the optimizer.
      beta: 5.0e-4                    # Strength of entropy regularization.
      epsilon: 0.2                    # Clipping parameter for PPO.
      lambd: 0.95                     # Lambda parameter for GAE (Generalized Advantage Estimation).
      num_epoch: 3                    # Number of passes through the experience buffer during gradient descent.
      learning_rate_schedule: linear  # How the learning rate changes over time.
    
    network_settings:
      normalize: true                 # Normalize observations.
      hidden_units: 512               # Number of units in each fully connected layer of the neural network.
      num_layers: 3                   # Number of hidden layers in the neural network.
      # vis_encode_type: simple       # Encoding type for visual observations (simple or resnet).
    
    reward_signals:
      extrinsic:
        gamma: 0.99                   # Discount factor for future rewards.
        strength: 1.0                 # Reward signal strength.
    
    keep_checkpoints: 50              # Number of model checkpoints to keep.
    max_steps: 50000000               # Total number of training steps.
    time_horizon: 512                 # Time horizon for accumulating experiences before making an update.
    summary_freq: 5000                # Frequency of writing statistics to TensorBoard.
    checkpoint_interval: 1000000      # Frequency of model checkpoint saving.
    threaded: false  
    
  worm_hard:
    trainer_type: ppo
    hyperparameters:
      batch_size: 1024                # Number of experiences used for each iteration of gradient descent.
      buffer_size: 10240              # Number of experiences to collect before updating the model.
      learning_rate: 3.0e-4           # Learning rate for the optimizer.
      beta: 5.0e-4                    # Strength of entropy regularization.
      epsilon: 0.2                    # Clipping parameter for PPO.
      lambd: 0.95                     # Lambda parameter for GAE (Generalized Advantage Estimation).
      num_epoch: 3                    # Number of passes through the experience buffer during gradient descent.
      learning_rate_schedule: linear  # How the learning rate changes over time.

    network_settings:
      normalize: true                 # Normalize observations.
      hidden_units: 512               # Number of units in each fully connected layer of the neural network.
      num_layers: 3                   # Number of hidden layers in the neural network.
      vis_encode_type: simple         # Encoding type for visual observations (simple or resnet).

    reward_signals:
      extrinsic:
        gamma: 0.99                   # Discount factor for future rewards.
        strength: 1.0                 # Reward signal strength.

    keep_checkpoints: 50              # Number of model checkpoints to keep.
    max_steps: 50000000               # Total number of training steps.
    time_horizon: 512                 # Time horizon for accumulating experiences before making an update.
    summary_freq: 5000                # Frequency of writing statistics to TensorBoard.
    checkpoint_interval: 1000000      # Frequency of model checkpoint saving.
    threaded: false  
    
  worm_hard_multiweapon:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512                 # Number of experiences used for each iteration of gradient descent.
      buffer_size: 10240              # Number of experiences to collect before updating the model.
      learning_rate: 3.0e-4           # Learning rate for the optimizer.
      beta: 0.005                     # Strength of entropy regularization.
      epsilon: 0.2                    # Clipping parameter for PPO.
      lambd: 0.95                     # Lambda parameter for GAE (Generalized Advantage Estimation).
      num_epoch: 5                    # Number of passes through the experience buffer during gradient descent.
      learning_rate_schedule: linear  # How the learning rate changes over time.

    network_settings:
      normalize: true                 # Normalize observations.
      hidden_units: 512               # Number of units in each fully connected layer of the neural network.
      num_layers: 3                   # Number of hidden layers in the neural network.
      vis_encode_type: simple         # Encoding type for visual observations (simple or resnet).

    reward_signals:
      extrinsic:
        gamma: 0.99                   # Discount factor for future rewards.
        strength: 1.0                 # Reward signal strength.

    keep_checkpoints: 50              # Number of model checkpoints to keep.
    max_steps: 50000000               # Total number of training steps.
    time_horizon: 128                 # Time horizon for accumulating experiences before making an update.
    summary_freq: 5000                # Frequency of writing statistics to TensorBoard.
    checkpoint_interval: 1000000      # Frequency of model checkpoint saving.
    threaded: false  
